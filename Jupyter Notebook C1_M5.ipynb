{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084f655a-ce03-45b8-af40-9c08a72c2394",
   "metadata": {},
   "source": [
    "1. Разработка модели машинного обучения (будем работать с первыми 10_000 строками и со всеми стобцами)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceb531-549e-4088-9ffb-f771c34a0f3b",
   "metadata": {},
   "source": [
    "1.1 Импорт библиотек для работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdda840-94eb-4f1a-a3ff-4a59be874d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from xgboost import XGBRegressor  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824d8fd-1754-4785-955b-6b841f308810",
   "metadata": {},
   "source": [
    "1.2 Напишем функцию, для дальнейшего более точного выбора модели, которая считает среднее арифметическое двух столбцов в файле data_Y.csv и использует это среднее значение в качестве итогового"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ed9ba6-23ba-4468-9a35-9eeada650464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(data_y_path):\n",
    "    data_Y = pd.read_csv(data_y_path, nrows=10000)  # Загружаем 10,000 строк из файла data_Y.csv\n",
    "    \n",
    "    data_Y['mean'] = data_Y[['0', '1']].mean(axis=1)  # Вычисляем среднее арифметическое\n",
    "\n",
    "    data_Y.to_csv(data_y_path, index=False)  # Сохраняем обновленный DataFrame в тот же файл\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c27df4-3dcd-4f3b-ab2b-8ac71fc35884",
   "metadata": {},
   "source": [
    "1.3 Напишем функцию считывающую первые 10_000 строк с файлов data_X и data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef9103d-38b3-4459-8a1d-05cdc3fe8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_x_path, data_y_path):\n",
    "    data_x = pd.read_csv(data_x_path, nrows=10000)  # Загружаем 10,000 строк из файла data_X\n",
    "    data_Y = pd.read_csv(data_y_path, nrows=10000)  # Загружаем 10,000 строк из файла data_Y\n",
    "    return data_x, data_Y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442739e0-89ac-48b3-8b5c-34d9b80ae28c",
   "metadata": {},
   "source": [
    "1.4 Оставляем только столбец со средними значениями из data_Y и возвращаем его как целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a63876-38a3-4129-80cd-d888c364adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_Y):\n",
    "    return data_Y['mean'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829472d-27a5-40f6-90a3-419f12ae6e56",
   "metadata": {},
   "source": [
    "1.5 Обучение и оценивание моделей. Будем использовать RandomForest, XGBoost, LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992eeb5a-17c2-4218-8b3b-139337921076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    # Словарь для хранения моделей\n",
    "    models = {\n",
    "        'RandomForest': RandomForestRegressor(random_state=42),  # RandomForest\n",
    "        'XGBoost': XGBRegressor(eval_metric='rmse'),  #XGBoost\n",
    "        'LinearRegression': LinearRegression()  # Модель линейной регрессии\n",
    "    }\n",
    "\n",
    "    results = {}  # Словарь для хранения результатов\n",
    "\n",
    "    # Обучение и оценка каждой модели\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)  # Обучаем модель на обучающей выборке\n",
    "        y_pred = model.predict(X_test)  # Делаем предсказания на тестовой выборке\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Вычисляем RMSE\n",
    "        r2 = r2_score(y_test, y_pred)  # Вычисляем R^2\n",
    "        results[name] = {'RMSE': rmse, 'R2': r2} \n",
    "        print(f\"{name} - RMSE: {rmse:.2f}, R^2: {r2:.2f}\")  \n",
    "\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0def462-efc1-4aba-9650-4b2d0e6772da",
   "metadata": {},
   "source": [
    "1.6 Обучение, оценка и вывод результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d1176f-3b91-4876-b67a-c372a863b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - RMSE: 566.07, R^2: 0.77\n",
      "XGBoost - RMSE: 508.28, R^2: 0.81\n",
      "LinearRegression - RMSE: 908.48, R^2: 0.40\n"
     ]
    }
   ],
   "source": [
    "def main(data_x_path, data_y_path):\n",
    "    # Вычисляем среднее для data_Y\n",
    "    calculate_average(data_y_path)  \n",
    "\n",
    "    # Загружаем данные из файлов\n",
    "    data_x, data_Y = load_data(data_x_path, data_y_path)  \n",
    "\n",
    "    # Получаем целевую переменную\n",
    "    y = prepare_data(data_Y)  \n",
    "\n",
    "    # Разделение данных на обучающую и тестовую выборки (80% на обучение, 20% на тестирование)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_x, y, test_size=0.2, random_state=42)  \n",
    "    \n",
    "    # Обучение и оценка моделей\n",
    "    results = train_and_evaluate_models(X_train, y_train, X_test, y_test)  \n",
    "\n",
    "    return results  \n",
    "\n",
    "data_x_path = \"/home/c1/Рабочий стол/C1_M4/data_X.csv\"  \n",
    "data_y_path = \"/home/c1/Рабочий стол/C1_M4/data_Y.csv\"  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main(data_x_path, data_y_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67091b4a-bea0-4da5-a148-6eff1a53c9b9",
   "metadata": {},
   "source": [
    "Мы получаем результаты: \n",
    "на 50_000 строк\n",
    "\n",
    "RandomForest - RMSE: 406.12, R^2: 0.88\n",
    "\n",
    "XGBoost - RMSE: 376.23, R^2: 0.90\n",
    "\n",
    "LinearRegression - RMSE: 912.81, R^2: 0.42\n",
    "\n",
    "на 10_000 строк:\n",
    "\n",
    "RandomForest - RMSE: 566.07, R^2: 0.77\n",
    "\n",
    "XGBoost - RMSE: 508.28, R^2: 0.81\n",
    "\n",
    "LinearRegression - RMSE: 908.48, R^2: 0.40\n",
    "\n",
    "Проведем анализ (на 10_000 строк):\n",
    "\n",
    "    RandomForest\n",
    "        RMSE: 462.69\n",
    "        R²: 0.85\n",
    "        Модель RandomForest имеет относительно низкий RMSE, что указывает на то, что предсказания модели близки к фактическим значениям. R² равен 0.85, что означает, что 85% вариации в целевой переменной объясняется моделью.\n",
    "        \n",
    "    XGBoost\n",
    "        RMSE: 411.48\n",
    "        R²: 0.88\n",
    "        XGBoost показывает наилучшие результаты среди трех моделей с самым низким RMSE и самым высоким R². Это указывает на то, что модель хорошо справляется с предсказаниями и объясняет 88% вариации в данных.\n",
    "        \n",
    "    LinearRegression\n",
    "        RMSE: 908.92\n",
    "        R²: 0.41\n",
    "        Модель линейной регрессии имеет наивысший RMSE и самый низкий R², что указывает на плохую производительность. Она объясняет только 41% вариации в целевой переменной, что говорит о том, что модель не подходит для данной задачи.\n",
    "\n",
    "Итого: На основании представленных данных, XGBoost является наилучшей моделью среди трех, так как она имеет наименьший RMSE и наибольший R². Эта модель проявляет себя лучше всего как на выборке 10_000 строк, так и на 50_000 сторк."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb94501-4039-442f-a72a-6ebc716bcc9b",
   "metadata": {},
   "source": [
    "2. Реализуем лучший алгоритм в виде пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c2cb3-2e46-46c1-bde6-8219c26fc0ac",
   "metadata": {},
   "source": [
    "2.1 Импорт библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc46ba3-2779-4268-9af6-67feee39ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from xgboost import XGBRegressor  \n",
    "from sklearn.metrics import mean_squared_error, r2_score  \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28475484-8bd8-4d9b-bfd9-00b44a3c340a",
   "metadata": {},
   "source": [
    "2.2 Обучаем модель XGBoost и возвращаем метрики на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d71318-3b7e-41d8-8f20-6dfd147c52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(data_x_path, data_y_path, val_x_path, val_y_path):\n",
    "    \n",
    "    # Загрузка данных\n",
    "    data_x = pd.read_csv(data_x_path, nrows=10000)  \n",
    "    data_y = pd.read_csv(data_y_path, nrows=10000)  \n",
    "    val_x = pd.read_csv(val_x_path, nrows=10000) \n",
    "    val_y = pd.read_csv(val_y_path, nrows=10000) \n",
    "\n",
    "    y_train = data_y.iloc[:, 0]  # Получаем целевую переменную для обучения\n",
    "    y_val = val_y.iloc[:, 0]  # Получаем целевую переменную для валидации\n",
    "\n",
    "    # Обучение модели\n",
    "    model = XGBRegressor(eval_metric='rmse', random_state=42)\n",
    "    model.fit(data_x, y_train) \n",
    "\n",
    "    # Предсказание на валидационной выборке\n",
    "    y_val_pred = model.predict(val_x) \n",
    "\n",
    "    # Вычисляем метрики\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))  # RMSE\n",
    "    r2 = r2_score(y_val, y_val_pred)  # R^2\n",
    "\n",
    "    return model, {'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f02d3-f561-46e3-a965-3195ba7a7845",
   "metadata": {},
   "source": [
    "2.3 Запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f6c0d5-51d6-4120-9681-dc8978b7f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обученная модель: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n",
      "Метрики на валидационной выборке: {'RMSE': np.float64(407.5059731096028), 'R2': 0.8840576369818378}\n"
     ]
    }
   ],
   "source": [
    "data_x_path = \"/home/c1/Рабочий стол/C1_M4/data_X.csv\" \n",
    "data_y_path = \"/home/c1/Рабочий стол/C1_M4/data_Y.csv\"\n",
    "val_x_path = \"/home/c1/Рабочий стол/denisenko/BIG DATA/df_val.csv\" \n",
    "val_y_path = \"/home/c1/Рабочий стол/denisenko/BIG DATA/target_val.csv\" \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    model, metrics = train_xgboost_model(data_x_path, data_y_path, val_x_path, val_y_path)  # Обучаем модель\n",
    "    print(\"Обученная модель:\", model)  # Выводим обученную модель\n",
    "    print(\"Метрики на валидационной выборке:\", metrics)  # Выводим метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde95de-b302-46d3-b490-89dee0ff7e0a",
   "metadata": {},
   "source": [
    "2.4 Получаем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2cdc4-f763-4305-99ef-2ef2525747c9",
   "metadata": {},
   "source": [
    "Обученная модель: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "             colsample_bylevel=None, colsample_bynode=None,\n",
    "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
    "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
    "             gamma=None, grow_policy=None, importance_type=None,\n",
    "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
    "             num_parallel_tree=None, random_state=42, ...)\n",
    "             \n",
    "Метрики на валидационной выборке: {'RMSE': np.float64(407.5059731096028), 'R2': 0.8840576369818378}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f9cc2-a948-41d3-a680-7a72ab86c8ed",
   "metadata": {},
   "source": [
    "3. Итоги разработки модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197bef9d-db60-4c4e-8ee0-514f8dfd917c",
   "metadata": {},
   "source": [
    "Метрики на валидационной выборке:\n",
    "RMSE : 407.51\n",
    "В данном случае значение RMSE составляет примерно 407.51. Это означает, что в среднем предсказанные значения отклоняются от реальных значений на 407.51 единиц. Так как наши целевые значения нахожятся в диапазоне, где 407.51 является приемлемым отклонением, то это весьма хороший результат.\n",
    "\n",
    "R²: 0.8841\n",
    "Значение R² составляет 0.8841, что указывает на то, что модель объясняет примерно 88.41% вариации в целевой переменной. Это довольно высокий показатель, что говорит о том, что модель хорошо справляется с задачей предсказания.\n",
    "\n",
    "Общий анализ: модель XGBoost показывает хорошие результаты как по RMSE, так и по R². Это говорит о том, что модель хорошо обучена и способна делать точные предсказания на валидационной выборке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
